{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import os\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330\n",
      "330\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "def data_loader(path):\n",
    "    \"\"\"\n",
    "        Loading data from the dataset. \n",
    "        returns:\n",
    "            data: list of audio files as numpy arrays\n",
    "            labels: list of labels for each audio file\n",
    "            sr: sample rate of the audio files\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Load the data\n",
    "    data = [sf.read(path + p)[0] for p in os.listdir(path) if p.endswith('.mp3')]\n",
    "    # Load the labels\n",
    "    labels = [p.split('_')[-1][:-4:1] for p in os.listdir(path) if p.endswith('.mp3')]\n",
    "\n",
    "    sr = sf.read(path + os.listdir(path)[0])[1]\n",
    "\n",
    "    return data, labels ,sr\n",
    "\n",
    "train_data, train_labels , sr = data_loader('data/train/')\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(train_labels))\n",
    "print(sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 73)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train_data[0].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class HMM(torch.nn.Module ):\n",
    "    \"\"\"\n",
    "    Hidden Markov Model with discrete transition probability\n",
    "    and multivariate Gaussian Emission Probabilities.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_states,n_features):\n",
    "        super(HMM, self).__init__()\n",
    "        # Number of states\n",
    "        self.n_states = n_states\n",
    "        # number of features\n",
    "        self.n_features = n_features\n",
    "\n",
    "        # Transition model in log space\n",
    "        self.transition_model = torch.nn.Parameter(torch.rand(n_states, n_states))\n",
    "        \n",
    "        # Emission model\n",
    "        self.emoission_model = EmissionModel(n_states,n_features)\n",
    "\n",
    "        # Initial state\n",
    "        self.initial_state = torch.nn.Parameter(torch.rand(n_states))\n",
    "\n",
    "        \n",
    "        self.cuda_available = torch.cuda.is_available()\n",
    "        if self.cuda_available:\n",
    "            self.device = torch.device('cuda')\n",
    "            self.cuda()  \n",
    "\n",
    "\n",
    "    def encode(self, data ,sr = 16000 , frame_length = 30, hop_length = 10):\n",
    "        \"\"\"\n",
    "            Encode the data using librosa\n",
    "            params:\n",
    "                data: list of one audio file as numpy arrays\n",
    "                sr: sample rate of the audio files, detault 16000\n",
    "                frame_length: length of the frame in milliseconds  \n",
    "                hop_length: hop length in milliseconds\n",
    "\n",
    "            returns:\n",
    "                encoded_data: list of encoded data as T x n_features matrix\n",
    "                tau : length of the frame in samples\n",
    "        \"\"\"\n",
    "        n_fft = int(sr * frame_length / 1000)\n",
    "        hop_length = int(sr * hop_length / 1000)\n",
    "\n",
    "        encoded_data = librosa.feature.mfcc(y=data, sr=sr,n_fft=n_fft,hop_length=hop_length,n_mfcc=self.n_features) \n",
    "\n",
    "        tau = n_fft\n",
    "        \n",
    "        return encoded_data.T , tau\n",
    "\n",
    "    \n",
    "    def train(self, data, n_iter = 100):\n",
    "        \"\"\"\n",
    "            Train the HMM model using Expectation Maximization\n",
    "            i.e. the Baum-Welch algorithm.\n",
    "            params:\n",
    "                data: audio files as numpy array\n",
    "                n_iter: number of EM iterations for training\n",
    "        \"\"\"\n",
    "\n",
    "        # Perform MFCC encoding\n",
    "        data , tau = self.encode(data)\n",
    "\n",
    "        T , n_features_data = data.shape\n",
    "\n",
    "        assert n_features_data == self.n_features\n",
    "\n",
    "        # Send data to GPU if available\n",
    "        if self.cuda_available:\n",
    "            data = torch.tensor(data).to(self.device)\n",
    "\n",
    "        # Initialize the model\n",
    "        self.initialize_initial_state()\n",
    "\n",
    "        # Initialize the transition model\n",
    "        self.initialize_transition_model()\n",
    "\n",
    "        # Initialize the emission model\n",
    "        self.initialize_emission_model()\n",
    "\n",
    "        for i in range(n_iter):\n",
    "            for x in data:\n",
    "                pass\n",
    "\n",
    "\n",
    "class EmissionModel(torch.nn.Module):\n",
    "    \"\"\"Emmision model for the HMM\"\"\"\n",
    "    def __init__(self,n_states,n_features):\n",
    "        super(EmissionModel, self).__init__()\n",
    "        self.n_states = n_states\n",
    "        self.n_features = n_features\n",
    "\n",
    "        self.gaussians = [torch.distributions.MultivariateNormal(torch.rand(n_features),torch.rand(n_features,n_features)) for i in range(n_states)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio-processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
